# RAG for Question Answering Task with LangChain

### RAG pipeline with LangChain 

[Retrieval-augmented generation (RAG)](https://huggingface.co/docs/transformers/model_doc/rag) searches documents through large language model (LLM) embedding and vectoring, creates the context from search results through clustering, and uses the context as an augmented prompt to inference a foundation model to get the answer. 

![img](https://github.com/yfgit2012/RAG-for-Question-Answering-with-LangChain/blob/main/assets/langchain.png)    

[LangChain](https://python.langchain.com/docs/get_started/introduction) is a framework for developing applications powered by language models. 

<br>

### Use cases  

* Basic RAG pipeline for question answering tasks 

* Conversational retrieval chain for chat history 

* Retrieve data from image 

* Document comparison powered by sequential chain 

<br>

### RAG with fine tuned LLM  

[My Blogpost](https://aws.amazon.com/blogs/machine-learning/a-generative-ai-powered-solution-on-amazon-sagemaker-to-help-amazon-eu-design-and-construction/)

![img](https://github.com/yfgit2012/RAG-for-Question-Answering-with-LangChain/blob/main/assets/RAG_ftllm_architecture.png)
       





